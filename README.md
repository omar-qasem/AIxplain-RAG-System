# Agentic RAG System for Government Regulations

This project implements a Retrieval-Augmented Generation (RAG) system to answer questions about government regulations, using data from Kaggle and the EPA. The system is designed to follow a precise, three-step process: **User Prompt → Document Search → Concise LLM Answer**.

## Project Overview

The core of this project is a RAG agent that leverages a TF-IDF vector store to find documents relevant to a user's query. The most relevant documents are then passed to a Large Language Model (LLM) to generate a **concise, context-grounded answer, free of unnecessary information.**

### Key Features

*   **Precise RAG Workflow:** User query is answered based *only* on retrieved documents.
*   **Concise Answering:** The LLM is strictly prompted to provide a direct answer without extraneous details.
*   **Data Ingestion:** Loads and combines data from AI Governance documents and EPA Guidance documents.
*   **Vector Store:** Creates a TF-IDF vector store for efficient document retrieval.

## Getting Started: Running the Demo

Follow these steps to set up the environment, download the necessary data, and run the improved RAG demo.

### 1. Prerequisites

*   Python 3.11+
*   An **OpenAI API Key** for the final LLM generation step.

### 2. Setup

**A. Clone the Repository**

```bash
git clone https://github.com/omar-qasem/AIxplain-RAG-System.git
cd AIxplain-RAG-System
```

**B. Install Required Packages**

```bash
pip install -r requirements.txt
```

**C. Configure API Key**

The RAG system uses an LLM (via the OpenAI API) to generate the final, concise answer.

1.  Create a file named `.env` in the root of the project directory.
2.  Add your OpenAI API key to the file in the following format:

    ```env
    OPENAI_API_KEY="YOUR_ACTUAL_OPENAI_KEY_HERE"
    ```

    *Note: The original `AIXPLAIN_API_KEY` environment variable is no longer used in the main demo script (`rag_system.py`), which now uses the standard `OPENAI_API_KEY` for the LLM step.*

### 3. Download Data

The RAG system relies on two external datasets.

```bash
# Download the EPA Guidance dataset (optional, as guidance_ow.csv is included)
python3 download_dataset.py

# Download the AI Governance dataset (REQUIRED)
python3 download_ai_governance_dataset.py
```

These scripts will place the necessary CSV files in the correct locations for the `rag_system.py` script to find them.

### 4. Run the Demo

The `rag_system.py` script is configured to run two example queries and demonstrate the full RAG workflow, including the final concise LLM answer.

```bash
python3 rag_system.py
```

**Expected Output Flow:**

The script will first load the data and build the vector store. For each query, you will see:

1.  The query being executed.
2.  The top 5 **Retrieved Documents** (the search step).
3.  The **Final Answer** (the analysis and concise answering step, generated by the LLM based on the retrieved documents).

---

## Project Structure

```
AIxplain-RAG-System/
├── .env                  # Your API Key configuration (add this file)
├── .gitignore
├── backend/              # (Existing directory)
├── cli_rag_agent.py      # (Existing CLI, not updated for LLM generation)
├── download_ai_governance_dataset.py
├── download_dataset.py
├── frontend/             # (Existing directory)
├── guidance_ow.csv
├── inspect_kaggle_csv.py
├── rag_system.py         # **Updated with full RAG workflow and LLM generation**
├── README.md             # This file
└── requirements.txt
```
